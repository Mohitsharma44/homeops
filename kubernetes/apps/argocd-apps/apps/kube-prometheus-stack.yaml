apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: monitoring
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: kube-prometheus-stack
    targetRevision: "81.x"
    helm:
      valuesObject:
        prometheus:
          prometheusSpec:
            enableRemoteWriteReceiver: true
            retention: 3d
            retentionSize: 15GB
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: ceph-block
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 20Gi
            externalLabels:
              cluster: minipcs
              environment: homelab
            serviceMonitorSelectorNilUsesHelmValues: false
            podMonitorSelectorNilUsesHelmValues: false
            ruleSelectorNilUsesHelmValues: false
            resources:
              requests:
                cpu: 500m
                memory: 2Gi
              limits:
                memory: 4Gi
            thanos:
              objectStorageConfig:
                existingSecret:
                  name: thanos-objstore-secret
                  key: objstore.yml
          thanosService:
            enabled: true
          thanosServiceMonitor:
            enabled: true
        grafana:
          ingress:
            enabled: true
            ingressClassName: nginx
            hosts:
              - grafana.sharmamohit.com
          sidecar:
            datasources:
              defaultDatasourceEnabled: false
            dashboards:
              enabled: true
              searchNamespace: monitoring
          additionalDataSources:
            - name: Thanos
              type: prometheus
              uid: thanos
              url: http://thanos-query.monitoring.svc:9090
              access: proxy
              isDefault: true
            - name: Loki
              type: loki
              uid: loki
              url: http://loki.monitoring.svc:3100
              access: proxy
              jsonData:
                httpHeaderName1: "X-Scope-OrgID"
                derivedFields:
                  - datasourceUid: tempo
                    matcherRegex: "(?:traceID|trace_id|traceid)=(\\w+)"
                    name: TraceID
                    url: "${__value.raw}"
              secureJsonData:
                httpHeaderValue1: "homelab"
            - name: Tempo
              type: tempo
              uid: tempo
              url: http://tempo.monitoring.svc:3200
              access: proxy
              jsonData:
                tracesToLogs:
                  datasourceUid: loki
                  filterByTraceID: true
          persistence:
            enabled: true
            storageClassName: ceph-block
            size: 2Gi
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              memory: 512Mi
        alertmanager:
          config:
            global:
              resolve_timeout: 5m
            route:
              receiver: homeassistant
              group_by: ['alertname', 'instance']
              group_wait: 3m
              group_interval: 10m
              repeat_interval: 6h
              routes:
                - receiver: "null"
                  matchers:
                    - alertname = "Watchdog"
                - receiver: homeassistant
                  matchers:
                    - severity = "critical"
                  repeat_interval: 1h
                  continue: true
                - receiver: homeassistant
                  matchers:
                    - severity = "warning"
                  repeat_interval: 6h
                  continue: true
                - receiver: slack
                  matchers:
                    - severity =~ "critical|warning"
                  repeat_interval: 6h
            receivers:
              - name: homeassistant
                webhook_configs:
                  - url: 'https://homeassistant.sharmamohit.com:8123/api/webhook/alertmanager-infra-alerts'
                    send_resolved: true
              - name: slack
                slack_configs:
                  - api_url_file: '/etc/alertmanager/secrets/alertmanager-slack-webhook/slack-webhook-url'
                    channel: '#homelab-alerts'
                    send_resolved: true
                    title: '{{ if eq .Status "firing" }}:fire:{{ else }}:white_check_mark:{{ end }} {{ .CommonLabels.alertname }}'
                    text: '{{ range .Alerts }}*{{ .Labels.severity | toUpper }}* - {{ .Labels.instance }}\n{{ .Annotations.summary }}\n{{ end }}'
              - name: "null"
          alertmanagerSpec:
            secrets:
              - alertmanager-slack-webhook
            retention: 120h
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: ceph-block
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 1Gi
            resources:
              requests:
                cpu: 100m
                memory: 128Mi
              limits:
                memory: 256Mi
        nodeExporter:
          enabled: true
        prometheus-node-exporter:
          resources:
            requests:
              cpu: 50m
              memory: 64Mi
            limits:
              memory: 128Mi
        kubeStateMetrics:
          enabled: true
        kube-state-metrics:
          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              memory: 256Mi
        additionalPrometheusRulesMap:
          infra-node-health:
            groups:
              - name: infra-node-health
                rules:
                  - alert: InfraHostDown
                    expr: up{job="integrations/unix", source="docker"} == 0
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "Host {{ $labels.instance }} is unreachable"
                  - alert: FilesystemSpaceLow
                    expr: |
                      (1 - node_filesystem_avail_bytes{fstype!~"tmpfs|overlay",source="docker"}
                      / node_filesystem_size_bytes{fstype!~"tmpfs|overlay",source="docker"}) > 0.85
                    for: 15m
                    labels:
                      severity: warning
                    annotations:
                      summary: "Filesystem {{ $labels.mountpoint }} on {{ $labels.instance }} is {{ $value | humanizePercentage }} full"
                  - alert: FilesystemSpaceCritical
                    expr: |
                      (1 - node_filesystem_avail_bytes{fstype!~"tmpfs|overlay",source="docker"}
                      / node_filesystem_size_bytes{fstype!~"tmpfs|overlay",source="docker"}) > 0.95
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "Filesystem {{ $labels.mountpoint }} on {{ $labels.instance }} is critically full ({{ $value | humanizePercentage }})"
                  - alert: FilesystemWillFillIn24h
                    expr: |
                      predict_linear(
                        node_filesystem_avail_bytes{fstype!~"tmpfs|overlay",source="docker"}[6h],
                        24*3600
                      ) < 0
                    for: 1h
                    labels:
                      severity: warning
                    annotations:
                      summary: "Filesystem {{ $labels.mountpoint }} on {{ $labels.instance }} will fill within 24 hours"
                  - alert: HighMemoryUsage
                    expr: |
                      (1 - node_memory_MemAvailable_bytes{source="docker"}
                      / node_memory_MemTotal_bytes{source="docker"}) > 0.90
                    for: 15m
                    labels:
                      severity: warning
                    annotations:
                      summary: "Memory usage on {{ $labels.instance }} is {{ $value | humanizePercentage }}"
                  - alert: HighCpuLoad
                    expr: |
                      (1 - avg by (instance)
                      (rate(node_cpu_seconds_total{mode="idle",source="docker"}[10m]))) > 0.90
                    for: 30m
                    labels:
                      severity: warning
                    annotations:
                      summary: "CPU usage on {{ $labels.instance }} is {{ $value | humanizePercentage }}"
          infra-smart-health:
            groups:
              - name: infra-smart-health
                rules:
                  - alert: SmartDiskUnhealthy
                    expr: smartctl_device_smart_status != 1
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "SMART health check FAILED on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartReallocatedSectorsGrowing
                    expr: |
                      increase(smartctl_device_attribute{attribute_name="Reallocated_Sector_Ct",attribute_value_type="raw"}[24h]) > 0
                    for: 5m
                    labels:
                      severity: warning
                    annotations:
                      summary: "Reallocated sectors increasing on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartPendingSectorsGrowing
                    expr: |
                      increase(smartctl_device_attribute{attribute_name="Current_Pending_Sector",attribute_value_type="raw"}[24h]) > 0
                    for: 5m
                    labels:
                      severity: warning
                    annotations:
                      summary: "Pending sectors increasing on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartDiskTemperatureHigh
                    expr: smartctl_device_temperature{temperature_type="current"} > 55
                    for: 10m
                    labels:
                      severity: warning
                    annotations:
                      summary: "Disk temperature {{ $value }}C on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartDiskTemperatureCritical
                    expr: smartctl_device_temperature{temperature_type="current"} > 65
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "Disk temperature critical {{ $value }}C on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartNvmeMediaErrors
                    expr: increase(smartctl_device_media_errors[24h]) > 0
                    for: 5m
                    labels:
                      severity: warning
                    annotations:
                      summary: "NVMe media errors increasing on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartNvmeCriticalWarning
                    expr: smartctl_device_critical_warning > 0
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "NVMe critical warning on {{ $labels.device }} ({{ $labels.instance }})"
                  - alert: SmartExporterDown
                    expr: up{job="smartctl"} == 0
                    for: 5m
                    labels:
                      severity: warning
                    annotations:
                      summary: "smartctl_exporter down on {{ $labels.instance }}"
          infra-zfs-health:
            groups:
              - name: infra-zfs-health
                rules:
                  - alert: ZfsPoolDegraded
                    expr: node_zfs_zpool_state{state="degraded", source="docker"} == 1
                    for: 5m
                    labels:
                      severity: critical
                    annotations:
                      summary: "ZFS pool {{ $labels.zpool }} is DEGRADED on {{ $labels.instance }}"
                  - alert: ZfsPoolFaulted
                    expr: node_zfs_zpool_state{state="faulted", source="docker"} == 1
                    for: 1m
                    labels:
                      severity: critical
                    annotations:
                      summary: "ZFS pool {{ $labels.zpool }} is FAULTED on {{ $labels.instance }}"
                  - alert: ZfsPoolUnavail
                    expr: node_zfs_zpool_state{state="unavail", source="docker"} == 1
                    for: 1m
                    labels:
                      severity: critical
                    annotations:
                      summary: "ZFS pool {{ $labels.zpool }} is UNAVAILABLE on {{ $labels.instance }}"
          infra-watchdog:
            groups:
              - name: infra-watchdog
                rules:
                  - alert: Watchdog
                    expr: vector(1)
                    labels:
                      severity: none
                    annotations:
                      summary: "Alertmanager is alive"
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true

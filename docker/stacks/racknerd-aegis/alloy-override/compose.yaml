# VPS-specific Alloy stack â€” full copy of shared config with CrowdSec metrics scraping added.
# Used instead of docker/stacks/shared/alloy/compose.yaml on racknerd-aegis only.
# Komodo doesn't support Docker Compose file merge (multiple -f), so this must be
# a complete standalone compose file. Keep service definition in sync with shared.
services:
  alloy:
    image: grafana/alloy:v1.13.1
    network_mode: host
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/host/rootfs:ro
      - alloy-data:/var/lib/alloy/data
      - traefik-logs:/var/log/traefik:ro
    configs:
      - source: alloy-config
        target: /etc/alloy/config.alloy
    security_opt:
      - no-new-privileges:true
      - apparmor:unconfined
    cap_drop:
      - ALL
    cap_add:
      - DAC_OVERRIDE
      - DAC_READ_SEARCH
      - SYS_PTRACE
    command:
      - run
      - /etc/alloy/config.alloy
      - --storage.path=/var/lib/alloy/data
      - --stability.level=generally-available
    env_file:
      - ../../shared/alloy/.env
    environment:
      INSTANCE_NAME: ${INSTANCE_NAME:-}
      PROMETHEUS_URL: ${PROMETHEUS_URL:-https://prometheus.sharmamohit.com/api/v1/write}
      LOKI_URL: ${LOKI_URL:-https://loki.sharmamohit.com/loki/api/v1/push}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:12345/-/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 768M
        reservations:
          memory: 384M

configs:
  alloy-config:
    content: |
        // ============================================================
        // Host metrics (node_exporter)
        // ============================================================

        prometheus.exporter.unix "host" {
          procfs_path = "/host/proc"
          sysfs_path  = "/host/sys"
          rootfs_path = "/host/rootfs"
        }

        prometheus.scrape "host" {
          targets         = prometheus.exporter.unix.host.targets
          forward_to      = [prometheus.relabel.instance.receiver]
          scrape_interval = "60s"
          job_name        = "node"
        }

        // ============================================================
        // Container metrics (cAdvisor)
        // ============================================================

        prometheus.exporter.cadvisor "containers" {
          docker_host = "unix:///var/run/docker.sock"
        }

        prometheus.scrape "containers" {
          targets         = prometheus.exporter.cadvisor.containers.targets
          forward_to      = [prometheus.relabel.instance.receiver]
          scrape_interval = "60s"
          job_name        = "cadvisor"
        }

        // ============================================================
        // CrowdSec metrics (VPS only)
        // ============================================================

        prometheus.scrape "crowdsec" {
          targets         = [{"__address__" = "localhost:6060"}]
          forward_to      = [prometheus.relabel.instance.receiver]
          scrape_interval = "60s"
          metrics_path    = "/metrics"
          job_name        = "crowdsec"
        }

        // ============================================================
        // Relabel: add instance label from INSTANCE_NAME env var
        // ============================================================

        prometheus.relabel "instance" {
          forward_to = [prometheus.remote_write.prometheus.receiver]

          rule {
            action       = "replace"
            target_label = "instance"
            replacement  = sys.env("INSTANCE_NAME")
          }
        }

        // ============================================================
        // Remote write: push metrics to K8s Prometheus
        // ============================================================

        prometheus.remote_write "prometheus" {
          external_labels = {
            source = "docker",
          }

          endpoint {
            url = sys.env("PROMETHEUS_URL")

            basic_auth {
              username = sys.env("BASIC_AUTH_USERNAME")
              password = sys.env("BASIC_AUTH_PASSWORD")
            }
          }
        }

        // ============================================================
        // Container logs via Docker
        // ============================================================

        discovery.docker "containers" {
          host = "unix:///var/run/docker.sock"
        }

        discovery.relabel "docker_logs" {
          targets = discovery.docker.containers.targets

          rule {
            source_labels = ["__meta_docker_container_name"]
            target_label  = "container"
          }
          rule {
            source_labels = ["__meta_docker_image_name"]
            target_label  = "image"
          }
          rule {
            action       = "replace"
            target_label = "instance"
            replacement  = sys.env("INSTANCE_NAME")
          }
        }

        loki.source.docker "containers" {
          host       = "unix:///var/run/docker.sock"
          targets    = discovery.relabel.docker_logs.output
          forward_to = [loki.write.loki.receiver]
        }

        // ============================================================
        // Traefik access logs via file (VPS only)
        // ============================================================
        // Access logs are written to a file, not stdout, so
        // loki.source.docker doesn't capture them. This ships the
        // JSON access log (with real client IPs) to Loki.

        local.file_match "traefik_access" {
          path_targets = [{"__path__" = "/var/log/traefik/access.log"}]
        }

        loki.source.file "traefik_access" {
          targets    = local.file_match.traefik_access.targets
          forward_to = [loki.process.traefik_access.receiver]
        }

        loki.process "traefik_access" {
          stage.static_labels {
            values = {
              container = "/aegis-traefik",
              job       = "traefik-access",
              instance  = sys.env("INSTANCE_NAME"),
            }
          }

          forward_to = [loki.write.loki.receiver]
        }

        // ============================================================
        // Loki write: push logs to K8s Loki
        // ============================================================

        loki.write "loki" {
          endpoint {
            url       = sys.env("LOKI_URL")
            tenant_id = "homelab"

            basic_auth {
              username = sys.env("BASIC_AUTH_USERNAME")
              password = sys.env("BASIC_AUTH_PASSWORD")
            }
          }
        }

volumes:
  alloy-data:
  traefik-logs:
    external: true
    name: aegis-gateway_traefik-logs
